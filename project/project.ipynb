{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.fact_checker_agent import FactCheckerAgent\n",
    "from network.socialnetwork import SocialNetworkEnv\n",
    "from agents.news_agent import NewsAgent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0: Points to -> 6, 1, 3\n",
      "Node 1: Points to -> 6, 2\n",
      "Node 2: Points to -> 7\n",
      "Node 3: Points to -> 4\n",
      "Node 4: Points to -> None\n",
      "Node 5: Points to -> 8, 2, 0, 1\n",
      "Node 6: Points to -> 2, 1, 0\n",
      "Node 7: Points to -> 8, 2\n",
      "Node 8: Points to -> 6\n",
      "Node 9: Points to -> 8, 6\n",
      "Node 10: Points to -> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "Node 11: Points to -> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "Node 12: Points to -> 0\n"
     ]
    }
   ],
   "source": [
    "network = SocialNetworkEnv(numConsumer=10)\n",
    "\n",
    "# created a fake and real info agent and add a few consumers to the network\n",
    "fAgent = NewsAgent(\"fake-information\", env=network, trustLevel=0)\n",
    "# fAgent2 = NewsAgent(\"fake-information\", env=network, trustLevel=0)\n",
    "# fAgent3 = NewsAgent(\"fake-information\", env=network, trustLevel=0)\n",
    "rAgent = NewsAgent(\"real-information\", env=network, trustLevel=0)\n",
    "fcAgent = FactCheckerAgent(\"fact-checker\", trustLevel=0.0, env=network)\n",
    "\n",
    "network.add_news_agents_to_network(agentType=fAgent)\n",
    "\n",
    "# network.add_news_agents_to_network(agentType=fAgent2)\n",
    "# network.add_news_agents_to_network(agentType=fAgent3)\n",
    "network.add_news_agents_to_network(agentType=rAgent)\n",
    "network.add_fact_checker_to_network(agentType=fcAgent)\n",
    "\n",
    "# print(\"---------------- Initial Graph ---------------\")\n",
    "network.print_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- epoch 0 ---------------------\n",
      "QTABLE [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "QTABLE [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'qVal1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m fAgent_action \u001b[38;5;241m=\u001b[39m fAgent\u001b[38;5;241m.\u001b[39mselect_action()\n\u001b[0;32m      5\u001b[0m rAgent_action \u001b[38;5;241m=\u001b[39m rAgent\u001b[38;5;241m.\u001b[39mselect_action()\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mqVal1\u001b[49m, qVal2)\n\u001b[0;32m      9\u001b[0m reward1, penalty1, state1, qVal1 \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mstep(fAgent_action, fAgent)\n\u001b[0;32m     10\u001b[0m reward2, penalty2, state2, qVal2 \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mstep(rAgent_action, rAgent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qVal1' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"\\n--------- epoch {i} ---------------------\")\n",
    "\n",
    "    fAgent_action = fAgent.select_action()\n",
    "    rAgent_action = rAgent.select_action()\n",
    "\n",
    "    reward1, penalty1, state1, qVal1 = network.step(fAgent_action, fAgent)\n",
    "    reward2, penalty2, state2, qVal2 = network.step(rAgent_action, rAgent)\n",
    "\n",
    "    print(qVal1, qVal2)\n",
    "\n",
    "    fAgent.update_q_value([state1, state2], fAgent_action, reward1, penalty1, qVal1)\n",
    "    rAgent.update_q_value([state1, state2], fAgent_action, reward2, penalty2, qVal2)\n",
    "    # reward, penalty = network.step(rAgent_action, rAgent)\n",
    "\n",
    "    # print(\"Fake Agent 2: \", end=\"\")\n",
    "    # reward22, penalty22 = network.step(fAgent_action2, fAgent2)\n",
    "    \n",
    "    # print(\"Fake Agent 3: \", end=\"\")\n",
    "    # reward3, penalty3 = network.step(fAgent_action3, fAgent3)\n",
    "\n",
    "    # print(\"Real Agent: \", end=\"\")\n",
    "    # reward2, penalty2 = network.step(rAgent_action, rAgent)\n",
    "\n",
    "    network.step_fact_checker(fcAgent, threshold=0.1)\n",
    "\n",
    "    network.render()\n",
    "    # network.print_graph()\n",
    "\n",
    "    # print(f\"\\nfake info - reward: {reward}, penalty : {penalty}\")\n",
    "    # print(f\"\\nfake info 2 - reward: {reward22}, penalty : {penalty22}\")\n",
    "    # print(f\"\\nfake info 3 - reward: {reward3}, penalty : {penalty3}\")\n",
    "    # print(f\"real info - reward: {reward2}, penalty : {penalty2}\")\n",
    "    # print(f\"fact checker - reward: {fcAgent.reward} penalty: {fcAgent.penalty}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
